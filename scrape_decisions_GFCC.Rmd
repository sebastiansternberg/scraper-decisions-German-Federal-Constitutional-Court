---
title: "Untitled"
author: "Arnold, Neunhoeffer, Sternberg"
date: "6 8 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(rvest)
library(magrittr)
library(stringr)


```


```{r}

paste("https://www.bundesverfassungsgericht.de/SiteGlobals/Forms/Suche/Entscheidungensuche_Formular.html?gtp=5403124_list%253D",i,"&language_=de", sep = "")



```


```{r}

pages <- c(1:3) # there are 721 pages to scrape

# getting the links to the decisions
links <- c()
for (i in 1:length(pages)){
  message("Getting decision ", i)
  html <- read_html(paste("https://www.bundesverfassungsgericht.de/SiteGlobals/Forms/Suche/Entscheidungensuche_Formular.html?gtp=5403124_list%253D",i,"&language_=de", sep = ""))
  href <- html %>% html_nodes(".relevance100+a") %>% html_attr("href")
  links <- c(links, href)
  message("taking a break")
  Sys.sleep(2)
}

links


```



```{r}

# select the decisions' links
decisions <- links[grep("^SharedDocs/Entscheidungen/",links)] %>% strsplit(";") %>% sapply("[", 1)

# the links must look like this: https://www.bundesverfassungsgericht.de/SharedDocs/Entscheidungen/DE/2019/07/rs20190730_2bvr168514.html

#generate the correct link be adding the necessary prefix to it:

decisions <- gsub("SharedDocs/", "https://www.bundesverfassungsgericht.de/SharedDocs/", decisions)

```


```{r}


# Testing for one text
case <- read_html("https://www.bundesverfassungsgericht.de/SharedDocs/Entscheidungen/DE/2019/05/qk20190524_1bvq004619.html")

header <- case %>% html_nodes("#navBreadcrumbs strong") %>% html_text()
cite <- case %>% html_nodes(".cite") %>% html_text()
chamber_senate <- case %>% html_nodes(".rr1") %>% html_text()

judge1 <- case %>% html_nodes(".absatz:nth-child(8) span") %>% html_text()
judge2 <- case %>% html_nodes(".absatz:nth-child(9) span") %>% html_text()
judge3 <- case %>% html_nodes(".absatz:nth-child(10) span") %>% html_text()

link_decision <- case %>% html_nodes(".cite a") %>% html_text()

aktenzeichen <- case %>% html_nodes(".az2 span") %>% html_text()


```

Looping over all decision links:


http://www.residualthoughts.com/2018/03/28/topic-analysis-of-tim-ferris-podcast-using-rvest/
```{r}

df_list <- list()

for(i in 1:length(decisions)){
  
  message("Scraping decision ", i)
  
  case <- read_html(decisions[i])

header <- case %>% html_nodes("#navBreadcrumbs strong") %>% html_text()
cite <- case %>% html_nodes(".cite") %>% html_text()
chamber_senate <- case %>% html_nodes(".rr1") %>% html_text()

judges_names <- case %>% html_nodes(".rr2 span") %>% html_text()
judge1 <- judges_names[1]
judge2 <- judges_names[2]
judge3 <- judges_names[3]

link_decision <- case %>% html_nodes(".cite a") %>% html_text()

aktenzeichen <- case %>% html_nodes(".az2 span") %>% html_text()

df_list[[i]] <-   data.frame(header = header, cite = cite, chamber_senate = chamber_senate,
                            judge1 = judge1, judge2 = judge2, judge3 = judge3,
                            link_decision = link_decision, aktenzeichen = aktenzeichen)

message("Iteration ", i, " of ", length(decisions),  " successful.")
message("taking a break")
Sys.sleep(5)
  
}

df_all_decisions  <- do.call("rbind", df_list)

save(df_all_decisions, file = "df_all_decisions.Rda")

```

## Data Cleaning

Clean the decisions. First drop the decisions with an "Urteil", because these are not Chamber decisions

```{r}

#load the 

chamber_decisions <- df_all_decisions[!grepl("Urteil", df_all_decisions$header), ]



```







